{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Price prediction code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTING IMPORTANT LIBRARIES\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import concatenate as conc\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, classification_report, precision_recall_fscore_support\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Nadam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Bidirectional\n",
    "from keras.utils import plot_model\n",
    "from keras import backend as K\n",
    "import os\n",
    "import time\n",
    "from datetime import timedelta\n",
    "os.environ[\"PATH\"] += os.pathsep + 'C:/Program Files (x86)/Graphviz2.38/bin/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_logarithmic_error(y_true, y_pred):\n",
    "        return K.sqrt(K.mean(K.square(K.log((y_pred - y_true), axis=-1))))\n",
    "    \n",
    "def percentage_change(inp):\n",
    "    arr =  ((np.diff(inp) / inp[:-1]))\n",
    "    return arr\n",
    "\n",
    "def binary(inp):\n",
    "    l = []\n",
    "    for i in range(len(inp)):\n",
    "        if i == 0:\n",
    "            continue\n",
    "        else:\n",
    "            if (inp[i] - inp[i-1]) > 0:\n",
    "                l.append(1)\n",
    "            else:\n",
    "                l.append(0)\n",
    "    return np.array(l)\n",
    "\n",
    "def strategy_profit(yhat, yt):\n",
    "    signal = np.array([1 if p == 1 else -1 for p in binary(yhat)]) # Creates a trading signal to buy if price rises, sell if price drops\n",
    "    signal = np.hstack((0,signal))\n",
    "    \n",
    "    df = pd.DataFrame() # Create dataframe for easier computation\n",
    "    \n",
    "    returns = yt.reshape((yt.shape[0], )) # create returns series from original data \n",
    "    returns[0] = 0\n",
    "    \n",
    "    df[\"return_strat\"] = (returns * signal) # daily returns strategy\n",
    "    np_return_strat = df[\"return_strat\"].values # numpy array of daily returns\n",
    "    \n",
    "    df[\"cumulative_return_strat\"] = ((1 + df['return_strat']).cumprod() - 1) * 100 # cumulative return of strategy when reinvesting entire portfolio value\n",
    "    df[\"return\"] = returns \n",
    "    df[\"cumulative_return\"] = (df[\"return\"].cumsum())*100 # Returns of the buy and hold strategy (buy at t=0 and hold untill t=end)\n",
    "    df[\"signal\"] = signal \n",
    "    return float(df.iloc[-1:][\"cumulative_return_strat\"] - df.iloc[-1:][\"cumulative_return\"]), (math.sqrt(365) * np.mean(np_return_strat) / np.std(np_return_strat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR REPRODUCIBILITY\n",
    "np.random.seed(7)\n",
    "\n",
    "# IMPORTING DATASET \n",
    "dataset = pd.read_csv('ethereum_trainval_dataset.csv')\n",
    "dataset = dataset.reindex(index = dataset.index[::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deleting unwanted columns\n",
    "del dataset[\"eth_supply\"]\n",
    "del dataset[\"eth_ethersupply\"]\n",
    "del dataset[\"eth_marketcap\"]\n",
    "del dataset[\"Unnamed: 0\"]\n",
    "del dataset[\"UnixTimeStamp\"]\n",
    "del dataset[\"eth_ens_register\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make price column the last one for easier use later on\n",
    "cols = list(dataset)\n",
    "cols[0], cols[11] = cols[11], cols[0]\n",
    "dataset = dataset.ix[:,cols]\n",
    "dataset = dataset[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accounting for blocktime being halved at index 809\n",
    "dataset[\"eth_blocktime\"].loc[809:] = dataset[809:][\"eth_blocktime\"] * 2\n",
    "dataset[\"eth_uncles\"].loc[809:] = dataset[809:][\"eth_uncles\"] / 2\n",
    "dataset[\"eth_blocks\"].loc[809:] = dataset[809:][\"eth_blocks\"] / 2\n",
    "dataset[\"eth_difficulty\"].loc[809:] = dataset[809:][\"eth_difficulty\"] * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop first 13 because of no price values\n",
    "dataset = dataset[13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to numpy array and normalize data.\n",
    "dataset = dataset.values\n",
    "dataset = dataset.astype(\"float32\")\n",
    "dataset_y = percentage_change(dataset[:, -1])\n",
    "scaler_mm = MinMaxScaler(feature_range=(0,1))\n",
    "scaler_z = StandardScaler()\n",
    "dataset_X = scaler_z.fit_transform(dataset[:, :-1])\n",
    "dataset_X = dataset_X[0:-1,: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(920,) (920, 11)\n"
     ]
    }
   ],
   "source": [
    "print(dataset_y.shape, dataset_X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(828, 1, 11)\n",
      "(828,)\n",
      "(92, 1, 11)\n",
      "(92,)\n"
     ]
    }
   ],
   "source": [
    "## Train/test split\n",
    "split = int(len(dataset)*0.9)\n",
    "\n",
    "train_X = dataset_X[:split, :]\n",
    "test_X = dataset_X[split:, :]\n",
    "\n",
    "train_y = dataset_y[:split,]\n",
    "test_y = dataset_y[:-split,]\n",
    "\n",
    "yt = test_y # for analysis later on\n",
    "\n",
    "# Reshape for LSTM\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(train_X.shape)\n",
    "print(train_y.shape)\n",
    "print(test_X.shape)\n",
    "print(test_y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model1_oleb(optimizer, loss_function, epochs = 10, batch_size = 1):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add((LSTM(64, input_shape=(1, 11), return_sequences = True))) \n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add((LSTM(128, input_shape=(1, 11), return_sequences = True)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add((LSTM(128, input_shape=(1, 11))))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(32))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # Compile and Run\n",
    "    model.compile(loss= loss_function , optimizer = optimizer) # Try SGD, adam, adagrad and compare!!!\n",
    "    model.fit(train_X, train_y, epochs = epochs, batch_size = batch_size, verbose=0)\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    return yhat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model1_neurons(n1, n2, n3, n4):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add((LSTM(n1, input_shape=(1, 11), return_sequences = True))) \n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add((LSTM(n2, input_shape=(1, 11), return_sequences = True)))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add((LSTM(n2, input_shape=(1, 11))))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n3))\n",
    "    model.add(Activation(\"relu\"))\n",
    "\n",
    "    model.add(Dense(n4))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # Compile and Run\n",
    "    model.compile(loss= \"mean_squared_error\" , optimizer = RMSprop(lr=0.0005)) # Try SGD, adam, adagrad and compare!!!\n",
    "    model.fit(train_X, train_y, epochs = 1000, batch_size = 64, verbose=0)\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model2_n(n1, n2):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add((LSTM(n1, input_shape=(1, 11), return_sequences= True)))\n",
    "    \n",
    "    model.add((LSTM(n2, input_shape=(1, 11))))\n",
    "\n",
    "    model.add(Dense(n3))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # Compile and Run\n",
    "    model.compile(loss= \"mean_squared_error\" , optimizer = RMSprop(lr=0.0005)) # Try SGD, adam, adagrad and compare!!!\n",
    "    model.fit(train_X, train_y, epochs = 2500, batch_size = 64, verbose=0)\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(50,50))\n",
    "\n",
    "# count = 1\n",
    "\n",
    "# d = {}\n",
    "\n",
    "# for n1 in [4, 8, 16, 32, 64, 128, 256]:\n",
    "#     for n2 in [4, 8, 16, 32, 64, 128, 256]:\n",
    "#         print(\"Starting to train model #\" + str(count))\n",
    "#         start_time = time.time()\n",
    "        \n",
    "#         yhat = fit_model2_n(n1, n2)\n",
    "\n",
    "#         plt.subplot(15, 4, count)\n",
    "#         plt.plot(yhat, \"g\", label = \"predicted\")\n",
    "#         plt.plot(yt, \"r\", label = \"real\")\n",
    "#         plt.title(\"n1: {} n2: {}\".format(str(n1), str(n2))) \n",
    "\n",
    "#         rmse_normalized = math.sqrt(mean_squared_error(yhat, yt))\n",
    "#         mae_normalized = mean_absolute_error(yhat, yt)\n",
    "#         excess_r, sharpe = strategy_profit(yhat, yt)\n",
    "\n",
    "#         d[\"n1: {} n2: {}\".format(str(n1), str(n2))] = \\\n",
    "#         [\"rmse: \" + str(rmse_normalized), \n",
    "#             \"mae: \" + str(mae_normalized),\n",
    "#                 precision_recall_fscore_support(binary(yhat), binary(yt), average = 'weighted'),\n",
    "#                     \"strategy profit in %: \" + str(excess_r),\n",
    "#                         \"Sharpe ratio: \" + str(sharpe),\n",
    "#                             yhat]\n",
    "\n",
    "#         print(\"Finished training model #{} with training time of: {} (h:mm:ss)\".format(str(count), timedelta(seconds=round(time.time() - start_time))))\n",
    "#         count += 1\n",
    "#         print(\"------------------\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig(\"test.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model2_oleb(o, l, e, b):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add((LSTM(256, input_shape=(1, 11)))) \n",
    "\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.add(Activation('linear'))\n",
    "\n",
    "    # Compile and Run\n",
    "    model.compile(loss = l, optimizer = o) # Try SGD, adam, adagrad and compare!!!\n",
    "    model.fit(train_X, train_y, epochs = e, batch_size = b, verbose=0)\n",
    "    yhat = model.predict(test_X)\n",
    "    \n",
    "    return yhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to train model #1\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "Blas GEMM launch failed : a.shape=(128, 64), b.shape=(64, 64), m=128, n=64, k=64\n\t [[Node: lstm_4/while/MatMul_6 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/RMSprop/gradients/lstm_4/while/MatMul_6_grad/MatMul\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_4/while/Switch_3:1, lstm_4/while/MatMul_6/Enter)]]\n\t [[Node: loss_1/mul/_161 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4287_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-a481b034e170>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_model1_oleb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-17-668b9b467687>\u001b[0m in \u001b[0;36mfit_model1_oleb\u001b[1;34m(optimizer, loss_function, epochs, batch_size)\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;31m# Compile and Run\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mloss_function\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# Try SGD, adam, adagrad and compare!!!\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m     \u001b[0myhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1040\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2659\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2660\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2661\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2662\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2663\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2629\u001b[0m                                 \u001b[0msymbol_vals\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2630\u001b[0m                                 session)\n\u001b[1;32m-> 2631\u001b[1;33m         \u001b[0mfetched\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2632\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2633\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1452\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n\u001b[1;32m-> 1454\u001b[1;33m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[0;32m   1455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1456\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__del__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python35\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[0;32m    517\u001b[0m             \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    518\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 519\u001b[1;33m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[0;32m    520\u001b[0m     \u001b[1;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \u001b[1;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m: Blas GEMM launch failed : a.shape=(128, 64), b.shape=(64, 64), m=128, n=64, k=64\n\t [[Node: lstm_4/while/MatMul_6 = MatMul[T=DT_FLOAT, _class=[\"loc:@training/RMSprop/gradients/lstm_4/while/MatMul_6_grad/MatMul\"], transpose_a=false, transpose_b=false, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](lstm_4/while/Switch_3:1, lstm_4/while/MatMul_6/Enter)]]\n\t [[Node: loss_1/mul/_161 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_4287_loss_1/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2f3a09dea90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gridsearch all but neurons\n",
    "n_epochs = [1000, 2500, 5000, 7500, 10000] # + 7500\n",
    "n_batch_size = [128, 64] # all good\n",
    "n_optimizers = [RMSprop(lr = 0.0005)]\n",
    "n_loss = [\"mean_squared_error\"] # = MAE, MSLE\n",
    "\n",
    "plt.figure(figsize=(30,30))\n",
    "\n",
    "count = 1\n",
    "\n",
    "d = {}\n",
    "\n",
    "for e in n_epochs:\n",
    "    for b in n_batch_size:\n",
    "        for o in n_optimizers:\n",
    "            for l in n_loss:\n",
    "                print(\"Starting to train model #\" + str(count))\n",
    "                start_time = time.time()\n",
    "                \n",
    "                yhat = fit_model1_oleb(o, l, e, b)\n",
    "                \n",
    "                plt.subplot(9, 4, count)\n",
    "                plt.plot(yhat, \"g\", label = \"predicted\")\n",
    "                plt.plot(yt, \"r\", label = \"real\")\n",
    "                plt.title(\"e: {} bs: {} o: {} l: {}\".format(str(e), str(b), str(o)[18:23], l)) \n",
    "                \n",
    "                rmse_normalized = math.sqrt(mean_squared_error(yhat, yt))\n",
    "                mae_normalized = mean_absolute_error(yhat, yt)\n",
    "                excess_r, sharpe = strategy_profit(yhat, yt)\n",
    "                \n",
    "                d[\"e: {} bs: {} o: {} l: {}\".format(str(e), str(b), str(o)[18:23], l)] = \\\n",
    "                [\"rmse: \" + str(rmse_normalized), \n",
    "                    \"mae: \" + str(mae_normalized),\n",
    "                        precision_recall_fscore_support(binary(yhat), binary(yt), average = 'weighted'),\n",
    "                            \"strategy profit in %: \" + str(excess_r),\n",
    "                                \"Sharpe ratio: \" + str(sharpe),\n",
    "                                    yhat]\n",
    "                \n",
    "                print(\"Finished training model #{} with training time of: {}\".format(str(count), timedelta(seconds=round(time.time() - start_time))))\n",
    "                count += 1\n",
    "                print(\"------------------\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(\"test.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Gridsearch neurons\n",
    "# n1l = [256]\n",
    "# n2l = [16, 32, 64, 128, 256]\n",
    "# n3l = [8, 16, 32, 64]\n",
    "# n4l = [2, 4, 8]\n",
    "\n",
    "# plt.figure(figsize=(60,60))\n",
    "\n",
    "# count = 1\n",
    "\n",
    "# d = {}\n",
    "\n",
    "# # FIT NEURONS IN NETWORK\n",
    "# for n1 in n1l:\n",
    "#     for n2 in n2l:\n",
    "#         for n3 in n3l:\n",
    "#             for n4 in n4l:\n",
    "#                 print(\"Starting to train model #\" + str(count))\n",
    "#                 start_time = time.time()\n",
    "#                 yhat = fit_model1_neurons(n1, n2, n3, n4)\n",
    "                \n",
    "#                 plt.subplot(15, 4, count)\n",
    "#                 plt.plot(yhat, \"g\", label = \"predicted\")\n",
    "#                 plt.plot(yt, \"r\", label = \"real\")\n",
    "#                 plt.title(\"n1: {} n2: {} n3: {} n4: {}\".format(str(n1), str(n2), str(n3), str(n4))) \n",
    "                \n",
    "#                 rmse_normalized = math.sqrt(mean_squared_error(yhat, yt))\n",
    "#                 mae_normalized = mean_absolute_error(yhat, yt)\n",
    "#                 excess_r, sharpe = strategy_profit(yhat, yt)\n",
    "                \n",
    "#                 d[\"n1: {} n2: {} n3: {} n4: {}\".format(str(n1), str(n2), str(n3), str(n4))] = \\\n",
    "#                 [\"rmse: \" + str(rmse_normalized), \n",
    "#                     \"mae: \" + str(mae_normalized),\n",
    "#                         precision_recall_fscore_support(binary(yhat), binary(yt), average = 'weighted'),\n",
    "#                             \"strategy profit in %: \" + str(excess_r),\n",
    "#                                 \"Sharpe ratio: \" + str(sharpe),\n",
    "#                                     yhat]\n",
    "                  \n",
    "#                 elapsed_time_secs = time.time() - start_time\n",
    "#                 print(\"Finished training model #{} with training time of: {}\".format(str(count), timedelta(seconds=round(elapsed_time_secs))))\n",
    "#                 count += 1\n",
    "                \n",
    "#                 print(\"------------------\")\n",
    "\n",
    "# plt.legend()\n",
    "# plt.savefig(\"test.png\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in d.items():\n",
    "    print(key, \"\\n\", value[0:5])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(d[\"e:10000 bs:128 o:RMSprl:mean_squared_error\"][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run tests to see how many plots needed\n",
    "c = 0\n",
    "\n",
    "for e in range(7):\n",
    "    for b in range(7):\n",
    "        c += 1\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "yt = test_y\n",
    "yhat = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat = d[\"e:500 bs:128 o:RMSprl:mean_squared_error\"][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(yhat, \"g\", label = \"predicted\")\n",
    "plt.plot(yt, \"r\", label = \"real\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rmse = math.sqrt(mean_squared_error(inv_yhat, inv_yt))\n",
    "#mae = mean_absolute_error(inv_yhat, inv_yt)\n",
    "rmse_normalized = math.sqrt(mean_squared_error(yhat, yt))\n",
    "mae_normalized = mean_absolute_error(yhat, yt)\n",
    "print(rmse_normalized, mae_normalized)\n",
    "# print(rmse, mae, \"original errors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(binary(yhat), binary(yt)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "returns = yt.reshape((yt.shape[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = np.array([1 if p == 1 else -1 for p in binary(yhat)])\n",
    "signal = np.hstack((0,signal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"return_strat\"] = (returns * signal) \n",
    "df[\"cumulative_return_strat\"] = ((1 + df['return_strat']).cumprod() - 1) * 100\n",
    "df[\"return\"] = returns \n",
    "df[\"cumulative_return\"] = (df[\"return\"].cumsum())*100\n",
    "df[\"signal\"] = signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(df[\"cumulative_return\"], \"r\", label = \"Buy and hold\")\n",
    "plt.plot(df[\"cumulative_return_strat\"], \"g\", label = \"Strategy\")\n",
    "plt.plot()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
